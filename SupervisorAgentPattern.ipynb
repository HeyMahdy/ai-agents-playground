{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeQzk9xo5BbrvjLps9eb8q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeyMahdy/ai-agents-playground/blob/main/SupervisorAgentPattern.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuotZWDm8uv4",
        "outputId": "e83a0e14-183d-413c-a02b-0cf96f8a80a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.4/948.4 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install -U langgraph langchain langchain-openai openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from typing import TypedDict, Annotated, Sequence, Dict, List, Any\n",
        "\n",
        "from langgraph.graph import StateGraph, END, add_messages\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# Set OpenAI API key (prompts once if not present)\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPENAI_API_KEY: \")\n",
        "\n",
        "# ----- State -----\n",
        "class MessageState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "\n",
        "class SupervisorState(MessageState):\n",
        "    supervisor_decision: str\n",
        "    task_assignments: Dict[str, List[str]]\n",
        "    agent_outputs: Dict[str, Any]\n",
        "    Schedule_Production_Agent_data: Dict[str, Any]\n",
        "    Query_Agent_data: Dict[str, Any]\n",
        "    Supply_Chain_Agent_data: Dict[str, Any]\n",
        "    Monitor_Sensors_Agent_data: Dict[str, Any]\n",
        "    workflow_stage: str\n",
        "    iterationCount: int\n",
        "    max_iteration: int\n",
        "    final_output: str\n",
        "\n",
        "# ----- LLM + Prompt -----\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"\"\"You are a Supervisor managing a team of agents:\n",
        "\n",
        "1. Schedule_Production_Agent - handles product capacity calculation and schedule CSV questions\n",
        "2. query_agent - performs database CRUD on the main database\n",
        "3. Supply_Chain_Agent - checks for supply chain issues\n",
        "\n",
        "Current State:\n",
        "- Current Agent: {current_agent}\n",
        "- Workflow Stage: {workflow_stage}\n",
        "- Iteration: {iterationCount}\n",
        "- Agent Outputs: {agent_outputs}\n",
        "- Task Assignments: {task_assignments}\n",
        "- Production Data: {Schedule_Production_Agent_data}\n",
        "- Sensor Data: {Monitor_Sensors_Agent_data}\n",
        "- Supply Chain Data: {Supply_Chain_Agent_data}\n",
        "\n",
        "Instructions:\n",
        "- Based on the current state and conversation, decide which agent should work next.\n",
        "- Your selection must be EXACTLY one of:\n",
        "  Schedule_Production_Agent\n",
        "  Supply_Chain_Agent\n",
        "  query_agent\n",
        "- If all tasks are complete, reply exactly: Done\n",
        "\"\"\"),\n",
        "    (\"human\", \"{task}\")\n",
        "])\n",
        "\n",
        "def create_supervisor_chain():\n",
        "    return prompt_template | llm | StrOutputParser()\n",
        "\n",
        "def choose_next_agent_from_text(text: str) -> str:\n",
        "    t = text.strip().lower()\n",
        "    if t == \"done\":\n",
        "        return \"Done\"\n",
        "    if \"schedule_production_agent\" in t:\n",
        "        return \"Schedule_Production_Agent\"\n",
        "    if \"supply_chain_agent\" in t:\n",
        "        return \"Supply_Chain_Agent\"\n",
        "    if \"query_agent\" in t:\n",
        "        return \"query_agent\"\n",
        "    return \"Schedule_Production_Agent\"\n",
        "\n",
        "# ----- Nodes -----\n",
        "def supervisor_agent(state: SupervisorState) -> Dict[str, Any]:\n",
        "    chain = create_supervisor_chain()\n",
        "    last_human = \"\"\n",
        "    for m in reversed(state[\"messages\"]):\n",
        "        if isinstance(m, HumanMessage):\n",
        "            last_human = m.content\n",
        "            break\n",
        "\n",
        "    decision_text = chain.invoke({\n",
        "        \"current_agent\": state.get(\"supervisor_decision\", \"\") or \"None\",\n",
        "        \"workflow_stage\": state[\"workflow_stage\"],\n",
        "        \"iterationCount\": state[\"iterationCount\"],\n",
        "        \"agent_outputs\": state[\"agent_outputs\"],\n",
        "        \"task_assignments\": state[\"task_assignments\"],\n",
        "        \"Schedule_Production_Agent_data\": state[\"Schedule_Production_Agent_data\"],\n",
        "        \"Monitor_Sensors_Agent_data\": state.get(\"Monitor_Sensors_Agent_data\", {}),\n",
        "        \"Supply_Chain_Agent_data\": state[\"Supply_Chain_Agent_data\"],\n",
        "        \"task\": last_human or \"Decide next agent.\"\n",
        "    })\n",
        "\n",
        "    next_agent = choose_next_agent_from_text(decision_text)\n",
        "    return {\n",
        "        \"supervisor_decision\": next_agent,\n",
        "        \"messages\": [AIMessage(content=f\"supervisor_decision: {next_agent}\")]\n",
        "    }\n",
        "\n",
        "def Schedule_Production_Agent(state: SupervisorState) -> Dict[str, Any]:\n",
        "    result = \"Production capacity is 100 units\"\n",
        "    new_outputs = dict(state[\"agent_outputs\"])\n",
        "    new_outputs[\"Schedule_Production_Agent\"] = result\n",
        "    new_sp_data = dict(state[\"Schedule_Production_Agent_data\"])\n",
        "    new_sp_data[\"capacity\"] = 100\n",
        "    return {\n",
        "        \"agent_outputs\": new_outputs,\n",
        "        \"Schedule_Production_Agent_data\": new_sp_data,\n",
        "        \"messages\": [AIMessage(content=result)],\n",
        "        \"iterationCount\": state[\"iterationCount\"] + 1\n",
        "    }\n",
        "\n",
        "def Supply_Chain_Agent(state: SupervisorState) -> Dict[str, Any]:\n",
        "    result = \"Supply chain is good\"\n",
        "    new_outputs = dict(state[\"agent_outputs\"])\n",
        "    new_outputs[\"Supply_Chain_Agent\"] = result\n",
        "    new_sc_data = dict(state[\"Supply_Chain_Agent_data\"])\n",
        "    new_sc_data[\"status\"] = \"good\"\n",
        "    return {\n",
        "        \"agent_outputs\": new_outputs,\n",
        "        \"Supply_Chain_Agent_data\": new_sc_data,\n",
        "        \"messages\": [AIMessage(content=result)],\n",
        "        \"iterationCount\": state[\"iterationCount\"] + 1\n",
        "    }\n",
        "\n",
        "def query_agent(state: SupervisorState) -> Dict[str, Any]:\n",
        "    result = \"crud operation done\"\n",
        "    new_outputs = dict(state[\"agent_outputs\"])\n",
        "    new_outputs[\"query_agent\"] = result\n",
        "    new_q_data = dict(state[\"Query_Agent_data\"])\n",
        "    new_q_data[\"last_operation\"] = \"crud\"\n",
        "    return {\n",
        "        \"agent_outputs\": new_outputs,\n",
        "        \"Query_Agent_data\": new_q_data,\n",
        "        \"messages\": [AIMessage(content=result)],\n",
        "        \"iterationCount\": state[\"iterationCount\"] + 1\n",
        "    }\n",
        "\n",
        "def router(state: SupervisorState) -> Dict[str, Any]:\n",
        "    return {\"messages\": [AIMessage(content=f\"routing to: {state['supervisor_decision']}\")]}\n",
        "\n",
        "# ----- Graph -----\n",
        "workflow = StateGraph(SupervisorState)\n",
        "workflow.add_node(\"supervisor_agent\", supervisor_agent)\n",
        "workflow.add_node(\"Schedule_Production_Agent\", Schedule_Production_Agent)\n",
        "workflow.add_node(\"Supply_Chain_Agent\", Supply_Chain_Agent)\n",
        "workflow.add_node(\"query_agent\", query_agent)\n",
        "workflow.add_node(\"router\", router)\n",
        "workflow.add_edge(\"supervisor_agent\", \"router\")\n",
        "\n",
        "def route_decision(state: SupervisorState) -> str:\n",
        "    return state[\"supervisor_decision\"]\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    route_decision,\n",
        "    {\n",
        "        \"Schedule_Production_Agent\": \"Schedule_Production_Agent\",\n",
        "        \"Supply_Chain_Agent\": \"Supply_Chain_Agent\",\n",
        "        \"query_agent\": \"query_agent\",\n",
        "        \"Done\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"Schedule_Production_Agent\", \"supervisor_agent\")\n",
        "workflow.add_edge(\"Supply_Chain_Agent\", \"supervisor_agent\")\n",
        "workflow.add_edge(\"query_agent\", \"supervisor_agent\")\n",
        "workflow.set_entry_point(\"supervisor_agent\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "# ----- Demo run -----"
      ],
      "metadata": {
        "id": "-HY6dKpU8_82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_query(user_input: str):\n",
        "    initial_state: SupervisorState = {\n",
        "        \"messages\": [HumanMessage(content=user_input)],\n",
        "        \"supervisor_decision\": \"\",\n",
        "        \"task_assignments\": {},\n",
        "        \"agent_outputs\": {},\n",
        "        \"Schedule_Production_Agent_data\": {},\n",
        "        \"Query_Agent_data\": {},\n",
        "        \"Supply_Chain_Agent_data\": {},\n",
        "        \"Monitor_Sensors_Agent_data\": {},\n",
        "        \"workflow_stage\": \"initial\",\n",
        "        \"iterationCount\": 0,\n",
        "        \"max_iteration\": 10,\n",
        "        \"final_output\": \"\"\n",
        "    }\n",
        "\n",
        "    result = graph.invoke(initial_state)\n",
        "\n",
        "    # Print conversation trace\n",
        "    for msg in result[\"messages\"]:\n",
        "        print(f\"{msg.type.upper()}: {msg.content}\")\n",
        "\n",
        "    # Print agent outputs for debugging\n",
        "    print(\"\\nFinal Agent Outputs:\", result[\"agent_outputs\"])\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "9nWY8S169cM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_query(\"Calculate production capacity\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcoZANI_-Gro",
        "outputId": "513685d6-2bc1-493c-cf1f-2506f783474d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN: Calculate production capacity\n",
            "AI: supervisor_decision: Schedule_Production_Agent\n",
            "AI: routing to: Schedule_Production_Agent\n",
            "AI: Production capacity is 100 units\n",
            "AI: supervisor_decision: Done\n",
            "AI: routing to: Done\n",
            "\n",
            "Final Agent Outputs: {'Schedule_Production_Agent': 'Production capacity is 100 units'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Calculate production capacity', additional_kwargs={}, response_metadata={}, id='20efb3d6-2472-4269-b852-38b8171937d5'),\n",
              "  AIMessage(content='supervisor_decision: Schedule_Production_Agent', additional_kwargs={}, response_metadata={}, id='7be56328-8599-452a-b0ec-19905a5bfc47'),\n",
              "  AIMessage(content='routing to: Schedule_Production_Agent', additional_kwargs={}, response_metadata={}, id='2ab73228-3f83-4334-bb3a-cb5160ddb73c'),\n",
              "  AIMessage(content='Production capacity is 100 units', additional_kwargs={}, response_metadata={}, id='3be640c0-08c6-49de-b2c6-9a576305bca9'),\n",
              "  AIMessage(content='supervisor_decision: Done', additional_kwargs={}, response_metadata={}, id='c2646d97-e4a8-4df3-bc7d-2f55da0f43fc'),\n",
              "  AIMessage(content='routing to: Done', additional_kwargs={}, response_metadata={}, id='21c3149a-0938-4706-ae38-c6f4b61fdd3a')],\n",
              " 'supervisor_decision': 'Done',\n",
              " 'task_assignments': {},\n",
              " 'agent_outputs': {'Schedule_Production_Agent': 'Production capacity is 100 units'},\n",
              " 'Schedule_Production_Agent_data': {'capacity': 100},\n",
              " 'Query_Agent_data': {},\n",
              " 'Supply_Chain_Agent_data': {},\n",
              " 'Monitor_Sensors_Agent_data': {},\n",
              " 'workflow_stage': 'initial',\n",
              " 'iterationCount': 1,\n",
              " 'max_iteration': 10,\n",
              " 'final_output': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}