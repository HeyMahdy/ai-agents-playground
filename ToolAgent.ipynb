{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3Vdrjo/xbcv4ddeBzFifW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeyMahdy/ai-agents-playground/blob/main/ToolAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PNluLIYSU3IT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install langchain-community==0.3.16\n",
        "%pip install langchain==0.3.23\n",
        "%pip install langchain-openai==0.3.14\n",
        "%pip install -q langgraph==0.2.57"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  langsmith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_uZqVuYmck0",
        "outputId": "6730ca0b-7262-45f1-dfde-02e99d45a08e"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.3.45)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.3)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.11.9)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langsmith) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langsmith) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "ZlAEdgrrQ0CJ",
        "outputId": "35a70268-49c4-491a-9db3-365d33f33ec8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed requests-2.32.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "4f422cc57a464308ab7da71cfabaec18"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
      ],
      "metadata": {
        "id": "Fl8EIlTrBTS9"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langgraph.graph import END, MessageGraph, StateGraph\n",
        "\n",
        "from typing import List, Sequence\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage, AIMessage"
      ],
      "metadata": {
        "id": "aJzlgm8OBsqK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
      ],
      "metadata": {
        "id": "QYHu9QTBByZJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool"
      ],
      "metadata": {
        "id": "WeDgHnnsVso_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import Literal"
      ],
      "metadata": {
        "id": "wRROzSugMsya"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "class Supplier(BaseModel):\n",
        "    supplier_id: str\n",
        "    name: str\n",
        "    location: str\n",
        "    lead_time_days: int"
      ],
      "metadata": {
        "id": "b_wa507aMtWU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Product(BaseModel):\n",
        "    sku: str\n",
        "    name: str\n",
        "    category: str\n",
        "    unit_of_measure: str\n",
        "    supplier_id: int"
      ],
      "metadata": {
        "id": "cUrFwUguNFOu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "import requests\n",
        "from pydantic import BaseModel, ValidationError\n"
      ],
      "metadata": {
        "id": "hwHDH1VXV4So"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def add_supply_data(\n",
        "    supplier_id: str,\n",
        "    name: str,\n",
        "    location: str,\n",
        "    lead_time_days: int\n",
        "):\n",
        "    \"\"\"\n",
        "    Send supplier data in database to save it.\n",
        "\n",
        "    This function acts as a tool to submit supplier information to the\n",
        "    FastAPI backend. It validates the input data using the `Supplier` Pydantic\n",
        "    model, sends a POST request to the endpoint, and handles possible errors\n",
        "    gracefully.\n",
        "\n",
        "    Args:\n",
        "        supplier_id (str): Unique identifier for the supplier.\n",
        "        name (str): Name of the supplier.\n",
        "        location (str): Physical location of the supplier.\n",
        "        lead_time_days (int): Average lead time for the supplier's products in days.\n",
        "\n",
        "    Returns:\n",
        "        dict: The JSON response from the FastAPI server if the request is\n",
        "        successful. The successful return format is:\n",
        "\n",
        "        {\n",
        "            \"supplier_id\": \"string\",\n",
        "            \"name\": \"string\",\n",
        "            \"location\": \"string\",\n",
        "            \"lead_time_days\": 0,\n",
        "            \"id\": 0\n",
        "        }\n",
        "\n",
        "        In case of errors, returns a dictionary with an 'error' key describing\n",
        "        the problem. Possible error cases:\n",
        "            - ValidationError: Input data is invalid.\n",
        "            - HTTPError: The API returned a bad HTTP status code (e.g., 405).\n",
        "            - RequestException: Network or request failure (e.g., timeout).\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Validate input using Pydantic\n",
        "        supplier = Supplier(\n",
        "            supplier_id=supplier_id,\n",
        "            name=name,\n",
        "            location=location,\n",
        "            lead_time_days=lead_time_days\n",
        "        )\n",
        "        payload = supplier.model_dump()  # get dict representation\n",
        "\n",
        "        # Make POST request to FastAPI\n",
        "        url = \"https://factoryai.onrender.com/suppliers/\"\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "        response = requests.post(url, json=payload, headers=headers, timeout=10)\n",
        "\n",
        "        # Raise exception for bad HTTP status codes\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Return JSON response\n",
        "        return response.json()\n",
        "\n",
        "    except ValidationError as ve:\n",
        "        return {\"error\": \"Invalid supplier data\", \"details\": ve.errors()}\n",
        "    except requests.exceptions.HTTPError as he:\n",
        "        return {\"error\": \"HTTP error occurred\", \"status_code\": response.status_code, \"details\": str(he)}\n",
        "    except requests.exceptions.RequestException as re:\n",
        "        return {\"error\": \"Request failed\", \"details\": str(re)}"
      ],
      "metadata": {
        "id": "G8MlvEW5XKR5"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_supply_data():\n",
        "    \"\"\"\n",
        "    Retrieve the list of suppliers database.\n",
        "\n",
        "    This function sends a GET request to the FastAPI backend to fetch all\n",
        "    suppliers. It handles HTTP errors and network issues gracefully.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: A list of supplier objects with the following format on\n",
        "        successful request:\n",
        "\n",
        "        [\n",
        "            {\n",
        "                \"supplier_id\": \"string\",\n",
        "                \"name\": \"string\",\n",
        "                \"location\": \"string\",\n",
        "                \"lead_time_days\": 0,\n",
        "                \"id\": 0\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        In case of errors, returns a dictionary with an 'error' key describing\n",
        "        the problem. Possible error cases:\n",
        "            - HTTPError: The API returned a bad HTTP status code (e.g., 405).\n",
        "            - RequestException: Network or request failure (e.g., timeout).\n",
        "    \"\"\"\n",
        "    try:\n",
        "\n",
        "        # Make POST request to FastAPI\n",
        "        url = \"https://factoryai.onrender.com/suppliers/\"\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "\n",
        "        # Raise exception for bad HTTP status codes\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Return JSON response\n",
        "        return response.json()\n",
        "\n",
        "    except ValidationError as ve:\n",
        "        return {\"error\": \"Invalid supplier data\", \"details\": ve.errors()}\n",
        "    except requests.exceptions.HTTPError as he:\n",
        "        return {\"error\": \"HTTP error occurred\", \"status_code\": response.status_code, \"details\": str(he)}\n",
        "    except requests.exceptions.RequestException as re:\n",
        "        return {\"error\": \"Request failed\", \"details\": str(re)}"
      ],
      "metadata": {
        "id": "aqtRYBCRXP2F"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def add_product_data(\n",
        "    sku: str,\n",
        "    name: str,\n",
        "    category: str,\n",
        "    unit_of_measure: str,\n",
        "    supplier_id: int\n",
        "):\n",
        "    \"\"\"\n",
        "    Send product data to database to store it.\n",
        "\n",
        "    This function acts as a tool to submit a new product to the FastAPI\n",
        "    backend. It validates input data using the `Product` Pydantic model,\n",
        "    sends a POST request to the endpoint, and handles errors gracefully.\n",
        "\n",
        "    Args:\n",
        "        sku (str): Unique SKU identifier for the product.\n",
        "        name (str): Name of the product.\n",
        "        category (str): Category or type of the product.\n",
        "        unit_of_measure (str): Unit in which the product is measured (e.g., kg, pcs).\n",
        "        supplier_id (int): ID of the supplier associated with this product.\n",
        "\n",
        "    Returns:\n",
        "        dict: The JSON response from the FastAPI server if successful. The\n",
        "        response format typically includes the product fields and its assigned\n",
        "        database ID. Example:\n",
        "\n",
        "        {\n",
        "            \"sku\": \"string\",\n",
        "            \"name\": \"string\",\n",
        "            \"category\": \"string\",\n",
        "            \"unit_of_measure\": \"string\",\n",
        "            \"supplier_id\": 0,\n",
        "            \"id\": 0\n",
        "        }\n",
        "\n",
        "        In case of errors, returns a dictionary with an 'error' key describing\n",
        "        the problem. Possible error cases:\n",
        "            - ValidationError: Input data is invalid.\n",
        "            - HTTPError: The API returned a bad HTTP status code (e.g., 405).\n",
        "            - RequestException: Network or request failure (e.g., timeout).\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Validate input using Pydantic\n",
        "        supplier = Supplier(\n",
        "            sku=sku,\n",
        "            name=name,\n",
        "            category=category,\n",
        "            unit_of_measure=unit_of_measure,\n",
        "            supplier_id=supplier_id\n",
        "\n",
        "        )\n",
        "        payload = supplier.model_dump()  # get dict representation\n",
        "\n",
        "        # Make POST request to FastAPI\n",
        "        url = \"https://factoryai.onrender.com/products/\"\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "        response = requests.post(url, json=payload, headers=headers, timeout=10)\n",
        "\n",
        "        # Raise exception for bad HTTP status codes\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Return JSON response\n",
        "        return response.json()\n",
        "\n",
        "    except ValidationError as ve:\n",
        "        return {\"error\": \"Invalid supplier data\", \"details\": ve.errors()}\n",
        "    except requests.exceptions.HTTPError as he:\n",
        "        return {\"error\": \"HTTP error occurred\", \"status_code\": response.status_code, \"details\": str(he)}\n",
        "    except requests.exceptions.RequestException as re:\n",
        "        return {\"error\": \"Request failed\", \"details\": str(re)}"
      ],
      "metadata": {
        "id": "Rw4n6N05YGnY"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_product_data():\n",
        "    \"\"\"\n",
        "    Retrieve the list of products from the database.\n",
        "\n",
        "    This function sends a GET request to the FastAPI `/products/` endpoint\n",
        "    to fetch all products. It handles HTTP errors and network issues gracefully.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: A list of product objects with the following format on\n",
        "        successful request:\n",
        "\n",
        "        [\n",
        "            {\n",
        "                \"sku\": \"string\",\n",
        "                \"name\": \"string\",\n",
        "                \"category\": \"string\",\n",
        "                \"unit_of_measure\": \"string\",\n",
        "                \"supplier_id\": 0,\n",
        "                \"id\": 0\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        In case of errors, returns a dictionary with an 'error' key describing\n",
        "        the problem. Possible error cases:\n",
        "            - HTTPError: The API returned a bad HTTP status code (e.g., 405).\n",
        "            - RequestException: Network or request failure (e.g., timeout).\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "\n",
        "        # Make POST request to FastAPI\n",
        "        url = \"https://factoryai.onrender.com/products/\"\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "        response = requests.get(url,params=\"\",headers=headers, timeout=10)\n",
        "\n",
        "        # Raise exception for bad HTTP status codes\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Return JSON response\n",
        "        return response.json()\n",
        "\n",
        "    except ValidationError as ve:\n",
        "        return {\"error\": \"Invalid supplier data\", \"details\": ve.errors()}\n",
        "    except requests.exceptions.HTTPError as he:\n",
        "        return {\"error\": \"HTTP error occurred\", \"status_code\": response.status_code, \"details\": str(he)}\n",
        "    except requests.exceptions.RequestException as re:\n",
        "        return {\"error\": \"Request failed\", \"details\": str(re)}"
      ],
      "metadata": {
        "id": "LC3-DWCIYK5w"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respon = get_product_data.invoke(input)"
      ],
      "metadata": {
        "id": "EHyEGh0Ol2U2"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(respon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ADCD_cimCUQ",
        "outputId": "1138d121-5ffa-4a70-9a30-aea4800928ae"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'sku': 'string', 'name': 'string', 'category': 'string', 'unit_of_measure': 'string', 'supplier_id': 6, 'id': 2}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools=[add_supply_data,get_product_data,get_supply_data,add_product_data]\n",
        "tools_by_name={ tool.name:tool for tool in tools}"
      ],
      "metadata": {
        "id": "sY2a4cpgaeLN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.prompts import MessagesPlaceholder , ChatPromptTemplate\n",
        "\n",
        "system_message = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\"\"\"\n",
        "\n",
        "    You are a helpful AI assistant that thinks step-by-step and uses tools when needed.\n",
        "\n",
        "When responding to queries:\n",
        "1. First, think carefully about what information you need.\n",
        "2. Use available tools if you require current data or specific capabilities.\n",
        "3. Provide clear, accurate, and helpful responses based on your reasoning and any tool results.\n",
        "\n",
        "Always explain your thinking process so the user can understand your approach.\n",
        "Be thorough, logical, and structured in your answers.\n",
        "Only fetch product information if user wants products data. Do NOT fetch supplier data\n",
        "also Only fetch supply information if user wants supply data. Do NOT products supplier data\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"),\n",
        "   MessagesPlaceholder(variable_name='scratch_pad')\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "QM9OXAcPawT-"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_react=system_message|llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "lgg2rymDdiio"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import (Annotated,Sequence,TypedDict)\n",
        "from langchain_core.messages import BaseMessage,ToolMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"The state of the agent.\"\"\"\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]"
      ],
      "metadata": {
        "id": "4qBSCGmHb1Te"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_model(state: AgentState):\n",
        "    \"\"\"Invoke the model with the current conversation state.\"\"\"\n",
        "    response = model_react.invoke({\"scratch_pad\": state[\"messages\"]})\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "EMIaFG0wcaM7"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "bOyHuRnBzu33"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "def tool_node(state: AgentState):\n",
        "    outputs = []\n",
        "\n",
        "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
        "        tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
        "\n",
        "        # tool_result is already a list of dicts\n",
        "        if isinstance(tool_result, list):\n",
        "            # Convert to JSON string, so LLM treats it as content\n",
        "            content = {\"text\": json.dumps(tool_result)}\n",
        "        else:\n",
        "            content = {\"text\": str(tool_result)}\n",
        "\n",
        "        outputs.append(\n",
        "            ToolMessage(\n",
        "                content=content,  # keep as list of dicts\n",
        "                name=tool_call[\"name\"],\n",
        "                tool_call_id=tool_call[\"id\"],\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return {\"messages\": outputs}\n"
      ],
      "metadata": {
        "id": "t7VAQykQt8ga"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def should_continue(state: AgentState):\n",
        "    \"\"\"Determine whether to continue with tool use or end the conversation.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    # If there is no function call, then we finish\n",
        "    if not last_message.tool_calls:\n",
        "        return \"end\"\n",
        "    # Otherwise if there is, we continue\n",
        "    else:\n",
        "        return \"continue\"\n"
      ],
      "metadata": {
        "id": "6th8ZIpxh4PY"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Define a new graph\n",
        "workflow4 = StateGraph(AgentState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow4.add_node(\"agent\", call_model)\n",
        "workflow4.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Add edges between nodes\n",
        "workflow4.add_edge(\"tools\", \"agent\")  # After tools, always go back to agent\n",
        "\n",
        "# Add conditional logic\n",
        "workflow4.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"continue\": \"tools\",  # If tools needed, go to tools node\n",
        "        \"end\": END,          # If done, end the conversation\n",
        "    },\n",
        ")\n",
        "\n",
        "# Set entry point\n",
        "workflow4.set_entry_point(\"agent\")\n",
        "\n",
        "# Compile the graph\n",
        "graph = workflow4.compile()"
      ],
      "metadata": {
        "id": "y9cXLyuuieU7"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_stream(stream):\n",
        "    \"\"\"Helper function for formatting the stream nicely.\"\"\"\n",
        "    for s in stream:\n",
        "        message = s[\"messages\"][-1]\n",
        "        if isinstance(message, tuple):\n",
        "            print(message)\n",
        "        else:\n",
        "            message.pretty_print()\n",
        "\n",
        "inputs = {\"messages\": [HumanMessage(content=\"Add a supplier with ID 'riheu', name 'nveriuvne', located in 'New York', and a lead time of 5 days?\")]}\n",
        "\n",
        "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-gVLqkNilPA",
        "outputId": "61550f27-d23e-45d4-bbd6-06879dbde821"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Add a supplier with ID 'riheu', name 'nveriuvne', located in 'New York', and a lead time of 5 days?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  add_supply_data (call_yW9OZzGLRvDxAwPwLJUMtB0r)\n",
            " Call ID: call_yW9OZzGLRvDxAwPwLJUMtB0r\n",
            "  Args:\n",
            "    supplier_id: riheu\n",
            "    name: nveriuvne\n",
            "    location: New York\n",
            "    lead_time_days: 5\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: add_supply_data\n",
            "\n",
            "{'text': '{\\'error\\': \\'Request failed\\', \\'details\\': \"HTTPSConnectionPool(host=\\'factoryai.onrender.com\\', port=443): Read timed out. (read timeout=10)\"}'}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "It seems that there was a timeout issue when trying to add the supplier data. This can happen due to network issues, server unavailability, or high server load.\n",
            "\n",
            "Would you like me to try adding the supplier again, or is there something else you would like to do?\n"
          ]
        }
      ]
    }
  ]
}